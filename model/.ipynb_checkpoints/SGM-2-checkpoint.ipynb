{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources Used\n",
    "- wget.download('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py')\n",
    "- Setup https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Tensorflow && git clone https://github.com/tensorflow/models\n",
    "#git config --global http.version HTTP/1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget.download('http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz')\n",
    "#!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {PRETRAINED_MODEL_PATH}\n",
    "#!cd {PRETRAINED_MODEL_PATH} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! Check this\n",
    "# make dir like below\n",
    "#copy pipline.config\n",
    "!mkdir {'Tensorflow\\workspace\\models\\\\'+CUSTOM_MODEL_NAME}\n",
    "!copy {'Tensorflow\\workspace\\pre-trained-models\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config'} {'Tensorflow\\workspace\\models\\my_ssd_mobnet'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "1.23.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = config['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature extractor of the detection model\n",
    "feature_extractor = detection_model._feature_extractor\n",
    "\n",
    "# Check if the model is in training mode\n",
    "print(\"Is training:\", feature_extractor._is_training)\n",
    "\n",
    "# Access the MobileNet base model name (if applicable)\n",
    "# Note: For SSD MobileNet, there may not be an attribute directly named as base model. \n",
    "# You might need to explore the structure to find equivalent attributes.\n",
    "print(\"Model name:\", feature_extractor._name)\n",
    "\n",
    "# Example of accessing backbone network (if applicable)\n",
    "# SSD MobileNet feature extractor typically uses MobileNetV2 or similar as its backbone\n",
    "print(\"Backbone network:\", feature_extractor._base_model_initialized)\n",
    "\n",
    "print(feature_extractor.classification_backbone)\n",
    "# Example of getting the feature map generator\n",
    "# SSD models often have methods to get specific feature layers or maps\n",
    "feature_maps = feature_extractor._extract_features\n",
    "print(\"Feature maps:\", feature_maps)\n",
    "\n",
    "# Access the conv definitions\n",
    "conv_defs = feature_extractor._conv_defs\n",
    "print(\"Conv defs:\", conv_defs)\n",
    "\n",
    "# Explore other attributes and methods as needed for your specific tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load a pre-trained MobileNetV2 model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# Print the summary to see the layers\n",
    "base_model.summary()\n",
    "\n",
    "# Get the layers\n",
    "layers = base_model.layers\n",
    "\n",
    "# Print the total number of layers\n",
    "print(\"Total number of layers:\", len(layers))\n",
    "\n",
    "# List layer names\n",
    "for i, layer in enumerate(layers):\n",
    "    print(f\"Layer {i}: {layer.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the feature extractor of the detection model\n",
    "feature_extractor = detection_model._feature_extractor\n",
    "\n",
    "# Print the layers attribute\n",
    "print(\"Layers:\", feature_extractor.layers)\n",
    "\n",
    "# Print the submodules attribute\n",
    "print(\"Submodules:\", feature_extractor.submodules)\n",
    "\n",
    "# Print the flattened layers\n",
    "print(\"Flattened layers:\", feature_extractor._flatten_layers())\n",
    "\n",
    "# Print trainable variables\n",
    "print(\"Trainable variables:\", feature_extractor.trainable_variables)\n",
    "\n",
    "# Print trainable weights\n",
    "print(\"Trainable weights:\", feature_extractor.trainable_weights)\n",
    "\n",
    "# Print all variables\n",
    "print(\"All variables:\", feature_extractor.variables)\n",
    "\n",
    "# Print all weights\n",
    "print(\"All weights:\", feature_extractor.weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000\"\"\".format(APIMODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "PATH_TO_CFG = \"Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config\"\n",
    "PATH_TO_CKPT = \"Tensorflow/workspace/models/my_ssd_mobnet\"\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'Tensorflow/workspace/annotations/label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = 'Tensorflow/workspace/images/processed_images/zm1_2_img003_jpg.rf.7b72906c2bc1c235f283e570fa9dccab.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread(IMAGE_PATHS)\n",
    "image_np = np.array(img)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "IMAGE_PATHS = IMAGE_PATHS  # Update with your image path\n",
    "\n",
    "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "\n",
    "image_np = load_image_into_numpy_array(IMAGE_PATHS)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# Convert to numpy arrays and remove batch dimension\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "# Filter detections to keep only the class with ID 1\n",
    "desired_class_id = 1\n",
    "indices = np.where(detections['detection_classes'] == desired_class_id)[0]\n",
    "\n",
    "filtered_boxes = detections['detection_boxes'][indices]\n",
    "filtered_classes = detections['detection_classes'][indices]\n",
    "filtered_scores = detections['detection_scores'][indices]\n",
    "\n",
    "# Count the number of bounding boxes with confidence scores over 70%\n",
    "confidence_threshold = 0.70\n",
    "high_confidence_indices = np.where(filtered_scores > confidence_threshold)[0]\n",
    "high_confidence_count = len(high_confidence_indices)\n",
    "\n",
    "# Filter out detections below the confidence threshold\n",
    "filtered_boxes = filtered_boxes[high_confidence_indices]\n",
    "filtered_classes = filtered_classes[high_confidence_indices]\n",
    "filtered_scores = filtered_scores[high_confidence_indices]\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    filtered_boxes,\n",
    "    filtered_classes + label_id_offset,\n",
    "    filtered_scores,\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=200,\n",
    "    min_score_thresh=confidence_threshold,\n",
    "    agnostic_mode=False\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image_np_with_detections)\n",
    "print('Done')\n",
    "plt.show()\n",
    "\n",
    "print(f'Number of bounding boxes with confidence over 70%: {high_confidence_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scalar tags: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key Loss was not found in Reservoir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable scalar tags:\u001b[39m\u001b[38;5;124m\"\u001b[39m, event_acc\u001b[38;5;241m.\u001b[39mTags()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalars\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m loss_events \u001b[38;5;241m=\u001b[39m \u001b[43mevent_acc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScalars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m accuracy_events \u001b[38;5;241m=\u001b[39m event_acc\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m loss_steps \u001b[38;5;241m=\u001b[39m [event\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m loss_events]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:479\u001b[0m, in \u001b[0;36mEventAccumulator.Scalars\u001b[1;34m(self, tag)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mScalars\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag):\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a summary tag, return all associated `ScalarEvent`s.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m      An array of `ScalarEvent`s.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mItems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorboard\\backend\\event_processing\\reservoir.py:110\u001b[0m, in \u001b[0;36mReservoir.Items\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutex:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets:\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was not found in Reservoir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n\u001b[0;32m    111\u001b[0m     bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets[key]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bucket\u001b[38;5;241m.\u001b[39mItems()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Key Loss was not found in Reservoir'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "log_dir = \"Tensorflow/workspace/models/my_ssd_mobnet/train\"\n",
    "event_acc = event_accumulator.EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# Check available tags\n",
    "print(\"Available scalar tags:\", event_acc.Tags()['scalars'])\n",
    "\n",
    "\n",
    "# Extract loss and accuracy\n",
    "loss_events = event_acc.Scalars('Loss')\n",
    "accuracy_events = event_acc.Scalars('Accuracy')\n",
    "\n",
    "loss_steps = [event.step for event in loss_events]\n",
    "loss_values = [event.value for event in loss_events]\n",
    "\n",
    "accuracy_steps = [event.step for event in accuracy_events]\n",
    "accuracy_values = [event.value for event in accuracy_events]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_steps, loss_values, label='Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_steps, accuracy_values, label='Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scalar tags: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key Loss/total_loss was not found in Reservoir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable scalar tags:\u001b[39m\u001b[38;5;124m\"\u001b[39m, event_acc\u001b[38;5;241m.\u001b[39mTags()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalars\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract and plot loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m loss_events \u001b[38;5;241m=\u001b[39m \u001b[43mevent_acc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScalars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss/total_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m accuracy_events \u001b[38;5;241m=\u001b[39m event_acc\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetrics/accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Example: Extract steps and values\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:479\u001b[0m, in \u001b[0;36mEventAccumulator.Scalars\u001b[1;34m(self, tag)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mScalars\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag):\n\u001b[0;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a summary tag, return all associated `ScalarEvent`s.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m      An array of `ScalarEvent`s.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mItems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorboard\\backend\\event_processing\\reservoir.py:110\u001b[0m, in \u001b[0;36mReservoir.Items\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutex:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets:\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was not found in Reservoir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n\u001b[0;32m    111\u001b[0m     bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets[key]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bucket\u001b[38;5;241m.\u001b[39mItems()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Key Loss/total_loss was not found in Reservoir'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "log_dir = \"Tensorflow/workspace/models/my_ssd_mobnet/train\"  # Replace with your actual logs directory\n",
    "event_acc = EventAccumulator(log_dir)\n",
    "event_acc.Reload()\n",
    "\n",
    "# Check available tags\n",
    "print(\"Available scalar tags:\", event_acc.Tags()['scalars'])\n",
    "\n",
    "# Extract and plot loss and accuracy\n",
    "loss_events = event_acc.Scalars('Loss/total_loss')\n",
    "accuracy_events = event_acc.Scalars('Metrics/accuracy')\n",
    "\n",
    "# Example: Extract steps and values\n",
    "loss_steps = [event.step for event in loss_events]\n",
    "loss_values = [event.value for event in loss_events]\n",
    "\n",
    "accuracy_steps = [event.step for event in accuracy_events]\n",
    "accuracy_values = [event.value for event in accuracy_events]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_steps, loss_values, label='Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_steps, accuracy_values, label='Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
